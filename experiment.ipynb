{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "about-heavy",
   "metadata": {},
   "source": [
    "## 0. Libarary 불러오기 및 경로설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cubic-scoop",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import confusion_matrix, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "from importlib import import_module\n",
    "import multiprocessing\n",
    "from dataset import BaseAugmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c57cc322",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/data/ephemeral/home/data/train/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22604746",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/level1/lib/python3.10/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# dataset 임포트\n",
    "from dataset import AgeModelDataset\n",
    "\n",
    "# dataset 불러오기\n",
    "dataset = AgeModelDataset(data_dir)\n",
    "class MyArg:\n",
    "    resize = [128, 96]\n",
    "\n",
    "# transform 임포트\n",
    "transform = BaseAugmentation(MyArg(), dataset)\n",
    "dataset.set_transform(transform)\n",
    "\n",
    "#\n",
    "age_loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=64,\n",
    "        num_workers=multiprocessing.cpu_count() // 2,\n",
    "        shuffle=True,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "        drop_last=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3b4f34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/level1/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/level1/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "  0%|          | 1/1012 [00:06<1:43:36,  6.15s/it]"
     ]
    }
   ],
   "source": [
    "# model import\n",
    "from models.age_model import SingleResNet50\n",
    "\n",
    "# model 불러오기\n",
    "model = SingleResNet50(3)\n",
    "\n",
    "model_loc = './BEST_age_model_expCutMix300epoch/age_model_best.pth'\n",
    "\n",
    "model.load_state_dict(torch.load(model_loc, map_location='cuda'))\n",
    "model.eval()\n",
    "\n",
    "labels = []\n",
    "preds = []\n",
    "for index, batch in enumerate(tqdm(age_loader)):\n",
    "    image, label = batch\n",
    "    image = image\n",
    "    label = label.long()\n",
    "    labels.extend(label.numpy())\n",
    "    pred = model(image) \n",
    "    preds.extend(torch.argmax(pred, dim=-1))\n",
    "    # 아래 주석을 사용하면 빠른 결과, 부정확한 score. (약 1분 소요)\n",
    "    # 그렇지 않으면 느린 결과, 정확한 score. (약 10분 소요)\n",
    "    # if index > 20:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4f5cc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(1), tensor(0), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(0), tensor(1), tensor(2), tensor(0), tensor(0), tensor(2), tensor(0), tensor(2), tensor(0), tensor(2), tensor(1), tensor(2), tensor(2), tensor(0), tensor(0), tensor(0), tensor(1), tensor(1), tensor(2), tensor(0), tensor(1), tensor(1), tensor(1), tensor(1), tensor(0), tensor(0), tensor(0), tensor(1), tensor(1), tensor(0), tensor(0), tensor(0), tensor(1), tensor(2), tensor(0), tensor(1), tensor(2), tensor(1), tensor(2), tensor(1), tensor(0), tensor(2), tensor(1), tensor(0), tensor(0), tensor(0), tensor(0), tensor(2), tensor(1), tensor(1), tensor(0), tensor(1), tensor(0), tensor(0), tensor(1), tensor(1), tensor(0), tensor(0), tensor(1), tensor(0), tensor(0), tensor(0), tensor(1), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(1), tensor(0), tensor(1), tensor(1), tensor(1), tensor(0), tensor(0), tensor(0), tensor(0), tensor(2), tensor(1), tensor(0), tensor(2), tensor(2), tensor(1), tensor(0), tensor(1), tensor(0), tensor(1), tensor(1), tensor(0), tensor(1), tensor(0), tensor(1), tensor(1), tensor(0), tensor(1), tensor(0), tensor(0), tensor(2), tensor(2), tensor(2), tensor(1), tensor(0), tensor(1), tensor(2), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(2), tensor(0), tensor(1), tensor(0), tensor(1), tensor(0), tensor(0), tensor(0), tensor(2), tensor(1), tensor(0), tensor(1), tensor(1), tensor(1), tensor(0), tensor(2), tensor(1), tensor(0), tensor(1), tensor(0), tensor(2), tensor(2), tensor(1), tensor(1), tensor(1), tensor(0), tensor(1), tensor(2), tensor(2), tensor(1), tensor(0), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(0), tensor(1), tensor(1), tensor(1), tensor(0), tensor(1), tensor(0), tensor(1), tensor(1), tensor(2), tensor(0), tensor(1), tensor(2), tensor(1), tensor(1), tensor(0), tensor(1), tensor(0), tensor(1), tensor(0), tensor(1), tensor(1), tensor(2), tensor(0), tensor(1), tensor(2), tensor(0), tensor(1), tensor(1), tensor(0), tensor(1), tensor(0), tensor(2), tensor(1), tensor(1), tensor(0), tensor(0), tensor(1), tensor(2), tensor(1), tensor(0), tensor(2), tensor(0), tensor(2), tensor(0), tensor(0), tensor(0), tensor(2), tensor(0), tensor(1), tensor(2), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(0), tensor(1), tensor(0), tensor(1), tensor(2), tensor(2), tensor(0), tensor(0), tensor(0), tensor(2), tensor(2), tensor(1), tensor(1), tensor(2), tensor(2), tensor(0), tensor(0), tensor(1), tensor(0), tensor(0), tensor(1), tensor(0), tensor(1), tensor(0), tensor(1), tensor(1), tensor(1), tensor(0), tensor(0), tensor(2), tensor(0), tensor(2), tensor(1), tensor(1), tensor(2), tensor(1), tensor(2), tensor(0), tensor(1), tensor(1), tensor(0), tensor(1), tensor(0), tensor(0), tensor(1), tensor(0), tensor(0), tensor(0), tensor(1), tensor(1), tensor(1), tensor(0), tensor(0), tensor(0), tensor(1), tensor(0), tensor(0), tensor(0), tensor(0), tensor(1), tensor(1), tensor(0), tensor(0), tensor(0), tensor(2), tensor(1), tensor(2), tensor(2), tensor(0), tensor(0), tensor(1), tensor(1), tensor(0), tensor(1), tensor(0), tensor(0), tensor(1), tensor(1), tensor(2), tensor(1), tensor(0), tensor(0), tensor(0), tensor(1), tensor(0), tensor(1), tensor(1), tensor(1), tensor(0), tensor(0), tensor(0), tensor(0), tensor(1), tensor(0), tensor(2), tensor(0), tensor(2), tensor(0), tensor(0), tensor(1), tensor(0), tensor(1), tensor(0), tensor(2), tensor(0), tensor(1), tensor(0), tensor(1), tensor(1), tensor(1), tensor(2), tensor(1), tensor(1), tensor(0), tensor(2), tensor(0), tensor(1), tensor(1), tensor(1), tensor(0), tensor(2), tensor(2), tensor(0), tensor(0), tensor(0), tensor(2), tensor(0), tensor(1), tensor(1), tensor(1), tensor(0), tensor(1), tensor(1), tensor(1), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(2), tensor(1), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(1), tensor(1), tensor(1), tensor(0), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(0), tensor(1), tensor(0), tensor(1), tensor(1), tensor(2), tensor(1), tensor(2), tensor(1), tensor(2), tensor(1), tensor(0), tensor(1), tensor(1), tensor(1), tensor(0), tensor(1), tensor(1), tensor(0), tensor(2), tensor(1), tensor(2), tensor(1), tensor(1), tensor(0), tensor(0), tensor(0), tensor(0), tensor(2), tensor(0), tensor(0), tensor(0), tensor(1), tensor(2), tensor(0), tensor(0), tensor(1), tensor(0), tensor(1), tensor(0), tensor(2), tensor(0), tensor(1), tensor(0), tensor(0), tensor(1), tensor(2), tensor(1), tensor(1), tensor(1), tensor(0), tensor(1), tensor(0), tensor(1), tensor(2), tensor(1), tensor(1), tensor(1), tensor(0), tensor(1), tensor(1), tensor(0), tensor(0), tensor(0), tensor(1), tensor(0), tensor(1), tensor(2), tensor(2), tensor(1), tensor(1), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0)]\n",
      "[1, 0, 1, 1, 1, 1, 1, 0, 1, 2, 0, 0, 2, 0, 2, 0, 2, 1, 2, 2, 0, 0, 0, 1, 1, 2, 0, 2, 1, 1, 1, 0, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 1, 2, 1, 2, 1, 0, 2, 1, 0, 0, 0, 0, 2, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 1, 1, 1, 0, 0, 0, 0, 2, 1, 0, 2, 2, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 2, 0, 0, 2, 2, 2, 1, 0, 1, 2, 1, 1, 1, 1, 1, 2, 0, 1, 0, 1, 0, 0, 0, 2, 1, 0, 1, 1, 1, 0, 2, 1, 0, 1, 0, 2, 2, 1, 1, 1, 0, 1, 2, 2, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 2, 0, 1, 2, 1, 1, 0, 2, 0, 1, 0, 1, 1, 2, 0, 1, 2, 0, 1, 0, 0, 1, 0, 2, 1, 0, 0, 0, 1, 2, 2, 0, 2, 0, 2, 0, 0, 0, 2, 0, 1, 2, 1, 1, 1, 1, 1, 0, 1, 0, 1, 2, 2, 0, 0, 0, 2, 2, 1, 1, 2, 2, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 2, 0, 2, 1, 1, 2, 1, 2, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 2, 1, 2, 2, 0, 0, 1, 1, 0, 1, 0, 0, 2, 1, 2, 1, 0, 0, 0, 1, 0, 1, 1, 2, 0, 0, 0, 0, 1, 0, 2, 0, 2, 0, 0, 1, 0, 1, 0, 2, 0, 1, 0, 1, 1, 1, 2, 1, 1, 0, 2, 0, 1, 1, 1, 0, 2, 2, 0, 0, 0, 2, 0, 1, 1, 1, 0, 1, 1, 2, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 2, 1, 2, 1, 2, 1, 0, 1, 1, 1, 0, 1, 1, 0, 2, 1, 2, 1, 1, 0, 0, 0, 0, 2, 0, 0, 0, 1, 2, 0, 0, 1, 0, 1, 0, 2, 0, 1, 0, 0, 1, 2, 1, 1, 1, 0, 1, 0, 1, 2, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 2, 2, 1, 1, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(preds)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df5d11a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.9588768115942029\n",
      "f1: 0.9682099466053434\n",
      "Confusion Matrix:\n",
      "[[182   2   0]\n",
      " [  0 176   0]\n",
      " [  0   9  71]]\n"
     ]
    }
   ],
   "source": [
    "recall = recall_score(labels, preds, average='macro')\n",
    "f1 = f1_score(labels, preds, average='macro')\n",
    "conf_matrix = confusion_matrix(labels, preds)\n",
    "\n",
    "print(\"Recall:\", recall)\n",
    "print(\"f1:\", f1)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "838a90a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './KANGSH_age_model_best.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
